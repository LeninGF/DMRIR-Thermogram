# Breast Cancer Detection from thermograms.
Breast cancer, the most common invasive cancer, causes deaths of thousands of women in the world every year. Early detection of the same is a remedy to lessen the death rate. Hence, screening of breast cancer in its early stage is utmost required. However, in the developing nations not many can afford the screening and detection procedures owing to its cost. Hence, an effective and less expensive way of detecting breast cancer is performed using thermography which, unlike other methods, can be used on women of various ages. To this end, we propose a computer aided breast cancer detection system that accepts thermal breast images to detect the same. Here, we use the pre-trained DenseNet121 model as a feature extractor to build a classifier for the said purpose. Before extracting features, we work on the original thermal breast images to get outputs using two edge detectors - Prewitt and Roberts. These two edge-maps along with the original image make the input to the DenseNet121 model as a 3-channel image. The thermal breast image dataset namely, Database for Mastology Research (DMR-IR) is used to evaluate performance of our model. We achieve the highest classification accuracy of 98.80\% on the said database, which outperforms many state-of-the-art methods, thereby confirming the superiority of the proposed model.
# Proposed Method
In this work, we have proposed a method which uses the concept of transferlearning for the detection of breast cancer from thermogram images. Our methoduses the DenseNet121 pre-trained model as a feature extractor and using it we havebuilt a classifier for detection of breast cancer. The reason for using the DenseNetarchitecture is based on the fact that this architecture diminishes the vanishinggradient problem. Along with using the pre-trained DenseNet121 model, we havealso used two edge detectors, Prewitt and Roberts, to extract edge information from  the  thermal  breast  images.  We  have  then  concatenated  the  outputs  fromthese  two  edge  detectors  with  the original  gray-scale  breast image  to obtain  anedge prominent 3-channel image. This is important because the pre-trained modelcan extract features from 3-channel images only. The overall architecture of theproposed work is shown in the figure below.
![mtap_one (1) (1) (1)](https://user-images.githubusercontent.com/46515291/155024223-367ee852-244b-4e04-b60d-46096ae593df.png)

# Edge detection
For breast cancer classification, it is important to look at the minute details like blood vessels and deformations on the breasts, in order to determine whether the patient has breast cancer or not and for that we have extracted edge information from the thermal images and combined these edge information with the original thermal images to make them more information rich. At this end, we have used two well-known edge detection techniques namely, Roberts and Prewitt to generate edges from original gray-scale thermogram images as these detectors help in preserving most of the minute edges. These two edge marked images are used with the original image to form a 3-channel image which is input to the pre-trained DenseNet121 model. 

Roberts and Prewitt edge detection techniques are known as a gradient based edge detection method. In gradient based edge detection technique, we convolve the image with horizontal and vertical derivative masks. These masks are also known as horizontal and vertical operators. These operators are used to perform quantitative analysis of the change in pixel intensities that leads to the identification of edges. They determine the presence of edges by calculating the difference between the corresponding pixels of an image which is analogous to the derivative in the signal domain. These two edge marked images are used with the original image to form a 3-channel image which is input to the pre-trained DenseNet121 model.

Original, Prewitt and Roberts edge detected maps are shown below,
![original (1) (1) (1)](https://user-images.githubusercontent.com/46515291/155024516-f91a6a13-d8a3-48ad-8501-26ddaaddc941.png)![prewitt (1) (1) (1)](https://user-images.githubusercontent.com/46515291/155024523-ae973f0b-a87b-40a1-aea1-7f4ee3c46d9a.png)![robert (1) (1) (1)](https://user-images.githubusercontent.com/46515291/155024528-1d8ebb5a-dbc2-4ac4-8d38-7c70991b84ae.png)

# Ablation Study
We have set learning rate as 2e-4 and number of nodes in FC layers as 4096. In this section we have made ablation study to ensure about the effectiveness of these selections as well as to search presence of any alternative(s). For experimentation, we have used 3-channel breast thermogram images, constructed using edge images generated using Roberts and Prewitt, and original gray-scale image. The results of ablation study with varying learning rate and number of nodes in the FC layers are shown below. In both the cases, we have used pre-trained DenseNet121 model for extracting features from the edge prominent 3-channel breast images and set the number of epochs to 50. These results indicate the superiority of the present choices of learning rate and number of nodes in the FC layers and hence, we have continued with these values for rest of the experiments.

Additionally, to decide an optimum number of epochs that should be used to train the classifier for rest of the experiments. For this experiment, we have used six pre-trained models- VGG16, VGG19, DenseNet121, DenseNet169, Inception and Xception to extract features from 3-channel edge-prominent breast images. From the results, we can see that by increasing the number of epochs beyond 50 leads to overfitting in the models. Hence, we set number of epochs to 50 for rest of the experiments.
![new-lr](https://user-images.githubusercontent.com/46515291/155024906-f24c9e4a-0e7e-48a3-b868-08f02b07d4ab.png)![new-nodes](https://user-images.githubusercontent.com/46515291/155024914-c51e8b92-6818-4825-9140-7f27f6febd26.png)![ir_models_loss (1) (1) (3)](https://user-images.githubusercontent.com/46515291/155024925-dcab5e85-abcd-4fb6-9c23-a0716319e5cc.png)![ir_models_accuracy (1) (1) (2)](https://user-images.githubusercontent.com/46515291/155024929-7d424293-8279-4c91-a2ca-952f3860809b.png)

# Performance comparison of different 3-channel image preparation techniques. The classifier in use is built on the pre-trained model of DenseNet121 as feature extractor.

![new-densenet21 (1)](https://user-images.githubusercontent.com/46515291/155025132-5bbec217-ed9c-4bf4-ba6f-048d03c8137a.png)

# Performance Comparison pf the present classifier when different pre-trained models are used to extract features from 3-channel edge-prominent images. Here we use the edge detector combination of Prewitt and Roberts

![new-pretrained (1)](https://user-images.githubusercontent.com/46515291/155025169-56d6b293-0505-4485-8503-c9a13f2b5700.png)

# Grad Cam analyis
Grad-CAM actually means gradient weighted class activation map which helpsus to understand the working of a deep learning model (here in our case a classifierâ€™sinternal working process). It does this by showing the regions of the input imageson which the model focuses on

![densenet121_affected (3) (1) (1)](https://user-images.githubusercontent.com/46515291/155025364-34d41a67-0cce-454a-98b7-8ba01e8125c4.png)![vgg19_affected (2) (1) (1)](https://user-images.githubusercontent.com/46515291/155025373-83bd78be-369e-4b12-803a-ad392ce8ea32.png)
