{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget http://visual.ic.uff.br/proeng/thiagoelias/database.rar\n\nimport os,glob\nimport numpy as np\nimport cv2\nimport glob\nimport pickle\nimport tensorflow as tf\nimport argparse\nimport re\nimport datetime\nfrom skimage.transform import rescale, resize, downscale_local_mean\nfrom tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\nfrom tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,MaxPooling2D,ReLU,Conv2DTranspose\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow.keras.backend as K\nfrom sklearn.svm import LinearSVC\nimport matplotlib.pyplot as plt\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom skimage.feature import hog,local_binary_pattern\nfrom skimage import data, exposure\nfrom skimage.transform import radon, rescale\nfrom skimage.filters import roberts, sobel, scharr, prewitt\nfrom skimage import feature\n\n!pip install rarfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-07T19:24:27.993629Z","iopub.execute_input":"2021-07-07T19:24:27.993986Z","iopub.status.idle":"2021-07-07T19:26:04.368315Z","shell.execute_reply.started":"2021-07-07T19:24:27.993910Z","shell.execute_reply":"2021-07-07T19:26:04.367316Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2021-07-07 19:24:28--  http://visual.ic.uff.br/proeng/thiagoelias/database.rar\nResolving visual.ic.uff.br (visual.ic.uff.br)... 200.20.15.38\nConnecting to visual.ic.uff.br (visual.ic.uff.br)|200.20.15.38|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 483263536 (461M)\nSaving to: ‘database.rar’\n\ndatabase.rar        100%[===================>] 460.88M  4.43MB/s    in 81s     \n\n2021-07-07 19:25:49 (5.71 MB/s) - ‘database.rar’ saved [483263536/483263536]\n\nCollecting rarfile\n  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\nInstalling collected packages: rarfile\nSuccessfully installed rarfile-4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"string = [138,179,180,181,192,198,202,204,209,210,213,240,241,245,249,250,251,255,257,259,261,263,264,270,400,450,500,550,600]\naffected_files_text = []\nfor f in string:\n    list1 = []\n    normal_dir = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/DOENTES/{}/Segmentadas\".format(f)\n    normal_dir_text = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/DOENTES/{}/Matrizes\".format(f)\n    dir1 = os.path.join(normal_dir,\"*.png\")\n    normal_files = glob.glob(dir1)\n    dir2 = os.path.join(normal_dir_text,\"*.txt\")\n    normal_files_text = glob.glob(dir2)\n\n    try:\n        for i in range(len(normal_files)):\n            list1.append(normal_files[i]+\"|\"+normal_files_text[i])\n    except:\n        print(f)\n            \n    affected_files_text.extend(list1)\n    \nstring2 = [1000,137,166,220,226,42,49,51,55,66,68,750,800,850,900]\n\nhealthy_files_text = []\nfor f in string2:\n    list2 = []\n    normal_dir = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/SAUDA╠üVEIS/{}/Segmentadas\".format(f)\n    normal_dir_text = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/SAUDA╠üVEIS/{}/Matrizes\".format(f)\n    dir1 = os.path.join(normal_dir,\"*.png\")\n    normal_files = glob.glob(dir1)\n    dir2 = os.path.join(normal_dir_text,\"*.txt\")\n    normal_files_text = glob.glob(dir2)\n    #print(len(normal_files),f)\n    try:\n        for i in range(len(normal_files)):\n            list2.append(normal_files[i]+\"|\"+normal_files_text[i])\n    except:\n        print(f)\n            \n    healthy_files_text.extend(list2)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.370089Z","iopub.execute_input":"2021-07-07T19:26:04.370441Z","iopub.status.idle":"2021-07-07T19:26:04.765699Z","shell.execute_reply.started":"2021-07-07T19:26:04.370400Z","shell.execute_reply":"2021-07-07T19:26:04.764869Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"181\n241\n1000\n137\n166\n220\n226\n42\n49\n51\n55\n66\n68\n750\n800\n850\n900\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"string = [650,700]\naffected_files_text2 = []\nfor f in string:\n    list1 = []\n    normal_dir = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/DOENTES/{}/Segmentadas\".format(f)\n    normal_dir_text = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/DOENTES/{}/Matrizes\".format(f)\n    dir1 = os.path.join(normal_dir,\"*.png\")\n    normal_files = glob.glob(dir1)\n    dir2 = os.path.join(normal_dir_text,\"*.txt\")\n    normal_files_text = glob.glob(dir2)\n\n    try:\n        for i in range(len(normal_files)):\n            list1.append(normal_files[i]+\"|\"+normal_files_text[i])\n    except:\n        print(f)\n            \n    affected_files_text2.extend(list1)\n    \nstring2 = [950]\n\nhealthy_files_text2 = []\nfor f in string2:\n    list2 = []\n    normal_dir = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/SAUDA╠üVEIS/{}/Segmentadas\".format(f)\n    normal_dir_text = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia/SAUDA╠üVEIS/{}/Matrizes\".format(f)\n    dir1 = os.path.join(normal_dir,\"*.png\")\n    normal_files = glob.glob(dir1)\n    dir2 = os.path.join(normal_dir_text,\"*.txt\")\n    normal_files_text = glob.glob(dir2)\n    #print(len(normal_files),f)\n    try:\n        for i in range(len(normal_files)):\n            list2.append(normal_files[i]+\"|\"+normal_files_text[i])\n    except:\n        print(f)\n            \n    healthy_files_text2.extend(list2)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.768893Z","iopub.execute_input":"2021-07-07T19:26:04.769157Z","iopub.status.idle":"2021-07-07T19:26:04.811277Z","shell.execute_reply.started":"2021-07-07T19:26:04.769130Z","shell.execute_reply":"2021-07-07T19:26:04.810561Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"950\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For ROI images","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"string_test = [1050,256,280,282,283,286]\nstring_test_2 = [108,50,64] \n\n\naffected_files_test = []\nfor f in string_test:\n    list2 = []\n    normal_dir = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/12 Novos Casos de Testes/DOENTES/{}/Segmentadas\".format(f)\n    normal_dir2 = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/12 Novos Casos de Testes/DOENTES/{}/Matrizes\".format(f)\n    dir1 = os.path.join(normal_dir,\"*.png\")\n    normal_files = glob.glob(dir1)\n    dir2 = os.path.join(normal_dir2,\"*.txt\")\n    normal_files_text = glob.glob(dir2)  \n    #print(len(normal_files),f)\n    try:\n        for i in range(len(normal_files)):\n            list2.append(normal_files[i]+\"|\"+normal_files_text[i])\n    except:\n        print(f)\n            \n    affected_files_test.extend(list2)\n\n\nhealthy_files_test = []\nfor f in string_test_2:\n    list2 = []\n    normal_dir = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/12 Novos Casos de Testes/SAUDA╠üVEIS/{}/Segmentadas\".format(f)\n    normal_dir2 = \"../input/thermal-images-for-breast-cancer-diagnosis-dmrir/Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/12 Novos Casos de Testes/SAUDA╠üVEIS/{}/Matrizes\".format(f)\n    dir1 = os.path.join(normal_dir,\"*.png\")\n    normal_files = glob.glob(dir1)\n    dir2 = os.path.join(normal_dir2,\"*.txt\")\n    normal_files_text = glob.glob(dir2)  \n    #print(len(normal_files),f)\n    try:\n        for i in range(len(normal_files)):\n            list2.append(normal_files[i]+\"|\"+normal_files_text[i])\n    except:\n        print(f)\n    healthy_files_test.extend(list2)\n\n#print(len(healthy_files))\nprint(len(healthy_files_text))\n#print(len(affected_files))\nprint(len(affected_files_text))\nprint(len(healthy_files_test))\n#print(len(healthy_files_test_text))\nprint(len(affected_files_test))\n#print(len(affected_files_test_text))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.812748Z","iopub.execute_input":"2021-07-07T19:26:04.813081Z","iopub.status.idle":"2021-07-07T19:26:04.902175Z","shell.execute_reply.started":"2021-07-07T19:26:04.813047Z","shell.execute_reply":"2021-07-07T19:26:04.901404Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"108\n50\n64\n300\n560\n60\n120\n","output_type":"stream"}]},{"cell_type":"code","source":"affected_files_test.extend(affected_files_text2)\nhealthy_files_test.extend(healthy_files_text2)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.904851Z","iopub.execute_input":"2021-07-07T19:26:04.905100Z","iopub.status.idle":"2021-07-07T19:26:04.910737Z","shell.execute_reply.started":"2021-07-07T19:26:04.905073Z","shell.execute_reply":"2021-07-07T19:26:04.909887Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(len(healthy_files_text))\n#print(len(healthy_files_test_text))\nprint(len(affected_files_text))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.913554Z","iopub.execute_input":"2021-07-07T19:26:04.913835Z","iopub.status.idle":"2021-07-07T19:26:04.923512Z","shell.execute_reply.started":"2021-07-07T19:26:04.913800Z","shell.execute_reply":"2021-07-07T19:26:04.922737Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"300\n560\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(healthy_files_test))\n#print(len(healthy_files_test_text))\nprint(len(affected_files_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.925706Z","iopub.execute_input":"2021-07-07T19:26:04.926071Z","iopub.status.idle":"2021-07-07T19:26:04.932951Z","shell.execute_reply.started":"2021-07-07T19:26:04.926036Z","shell.execute_reply":"2021-07-07T19:26:04.931851Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"81\n160\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dic = {}\nfor f in affected_files_text:\n  train_dic[f] = [1,0]\nfor f in healthy_files_text:\n  train_dic[f] = [0,1]\n\n\ntest_dic = {}\nfor f in affected_files_test:\n  test_dic[f] = [1,0]\nfor f in healthy_files_test:\n  test_dic[f] = [0,1]","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.935914Z","iopub.execute_input":"2021-07-07T19:26:04.936396Z","iopub.status.idle":"2021-07-07T19:26:04.943945Z","shell.execute_reply.started":"2021-07-07T19:26:04.936262Z","shell.execute_reply":"2021-07-07T19:26:04.943196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import random\nl_train = list(train_dic.items())\nrandom.shuffle(l_train)\n\n\nimport random\nl_test = list(test_dic.items())\nrandom.shuffle(l_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.945586Z","iopub.execute_input":"2021-07-07T19:26:04.945934Z","iopub.status.idle":"2021-07-07T19:26:04.952818Z","shell.execute_reply.started":"2021-07-07T19:26:04.945899Z","shell.execute_reply":"2021-07-07T19:26:04.951969Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# #ROBERTS AND SOBEL","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data = []\nnormal_data = []\nlabels = []\nfor i in range(len(l_train)):\n    file_name,label = l_train[i]\n    a,b = file_name.split(\"|\")\n    img = cv2.imread(a)\n    arr_1 = np.empty((480,640))\n\n    try:\n        with open(b,\"r\") as f:\n            arr = f.readlines()\n            for i in range(len(arr)):\n                arr[i] = arr[i].replace(\",\", \".\")\n                arr_2 = []\n                for j in arr[i].split():\n                    arr_2.append(float(j))\n                arr_1[i] = np.asarray(arr_2) \n        img = np.asarray(img)\n        arr_1 = np.asarray(arr_1)\n        edge_roberts = roberts(arr_1)\n        edge_sobel = sobel(arr_1)\n        img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n        arr_img = cv2.resize(arr_1,(224,224),interpolation = cv2.INTER_CUBIC)\n        r_img = cv2.resize(edge_roberts,(224,224),interpolation = cv2.INTER_CUBIC)\n        s_img = cv2.resize(edge_sobel,(224,224),interpolation = cv2.INTER_CUBIC)\n        arr_3 = np.expand_dims(arr_img,axis = -1)\n        arr_2 = np.expand_dims(r_img,axis = -1)\n        arr_1 = np.expand_dims(s_img,axis = -1)\n        img2 = np.concatenate((arr_3,arr_2,arr_1),axis = -1)\n        height, width = img.shape[:2]\n        img2 = img2.astype('float32')/255.0\n        img = img.astype('float32')/255.0\n        data.append(img2)\n        normal_data.append(img)\n        labels.append(label)\n\n    except:\n        print(i,file_name)\n        print(\"Not possible\")  \ntrain_data = np.array(data)\nprint(train_data.shape)\nnormal_data = np.array(normal_data)\nprint(normal_data.shape)\n\ntrain_labels = np.array(labels)\nprint(train_labels.shape)    \n\nprint('^_^-training data finished-^_^')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:26:04.954194Z","iopub.execute_input":"2021-07-07T19:26:04.954635Z","iopub.status.idle":"2021-07-07T19:29:04.500401Z","shell.execute_reply.started":"2021-07-07T19:26:04.954597Z","shell.execute_reply":"2021-07-07T19:29:04.499471Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(860, 224, 224, 3)\n(860, 224, 224, 3)\n(860, 2)\n^_^-training data finished-^_^\n","output_type":"stream"}]},{"cell_type":"code","source":"test_text = []\ndata = []\nlabels = []\nfor i in range(len(l_test)):\n    file_name,label = l_test[i]\n    a,b = file_name.split(\"|\")\n    img = cv2.imread(a)\n    arr_1 = np.empty((480,640))\n    try:\n        with open(b,\"r\") as f:\n            arr = f.readlines()\n            for i in range(len(arr)):\n                arr_2 = []\n                for j in arr[i].split():\n                    arr_2.append(float(j))\n                arr_1[i] = np.asarray(arr_2) \n        img = np.asarray(img)\n        arr_1 = np.asarray(arr_1) \n        edge_roberts = roberts(arr_1)\n        edge_sobel = sobel(arr_1) \n        img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n        arr_img = cv2.resize(arr_1,(224,224),interpolation = cv2.INTER_CUBIC)\n        s_img = cv2.resize(edge_roberts,(224,224),interpolation = cv2.INTER_CUBIC)\n        r_img = cv2.resize(edge_sobel,(224,224),interpolation = cv2.INTER_CUBIC)\n        arr_3 = np.expand_dims(arr_img,axis = -1)\n        arr_2 = np.expand_dims(r_img,axis = -1)\n        arr_1 = np.expand_dims(s_img,axis = -1)\n        img2 = np.concatenate((arr_3,arr_2,arr_1),axis = -1)\n        height, width = img.shape[:2]\n        img2 = img2.astype('float32')/255.0\n        img = img.astype('float32')/255.0\n        test_text.append(img2)\n        data.append(img)\n        labels.append(label)\n\n    except:\n        print(i,file_name)\n        print(\"Not possible\")  \n  \n       \ntest_data = np.array(data)\nprint(test_data.shape)\ntest_text = np.array(test_text)\nprint(test_text.shape)\ntest_labels = np.array(labels)\nprint(test_labels.shape)    \n\nprint('^_^-testing data finished-^_^')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:29:04.501709Z","iopub.execute_input":"2021-07-07T19:29:04.502202Z","iopub.status.idle":"2021-07-07T19:29:54.962402Z","shell.execute_reply.started":"2021-07-07T19:29:04.502164Z","shell.execute_reply":"2021-07-07T19:29:54.960889Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(241, 224, 224, 3)\n(241, 224, 224, 3)\n(241, 2)\n^_^-testing data finished-^_^\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **#CANNY AND roberts**","metadata":{}},{"cell_type":"code","source":"from skimage.transform import rescale, resize, downscale_local_mean\ndata = []\nnormal_data = []\nlabels = []\nfor i in range(len(l_train)):\n    file_name,label = l_train[i]\n    a,b = file_name.split(\"|\")\n    img = cv2.imread(a)\n    arr_1 = np.empty((480,640))\n\n    try:\n        with open(b,\"r\") as f:\n            arr = f.readlines()\n            for i in range(len(arr)):\n                arr[i] = arr[i].replace(\",\", \".\")\n                arr_2 = []\n                for j in arr[i].split():\n                    arr_2.append(float(j))\n                arr_1[i] = np.asarray(arr_2) \n        img = np.asarray(img)\n        arr_1 = np.asarray(arr_1)\n        edge_roberts = roberts(arr_1)\n        edge_canny = feature.canny(arr_1, sigma=1)\n        edge_canny = np.asarray(edge_canny)\n        \n        img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n        arr_img = cv2.resize(arr_1,(224,224),interpolation = cv2.INTER_CUBIC)\n        r_img = cv2.resize(edge_roberts,(224,224),interpolation = cv2.INTER_CUBIC)\n        s_img = resize(edge_canny, (224,224),anti_aliasing=True)\n        #s_img = cv2.resize(edge_canny,(224,224),interpolation = cv2.INTER_CUBIC)\n        \n        arr_3 = np.expand_dims(arr_img,axis = -1)\n        arr_2 = np.expand_dims(r_img,axis = -1)\n        arr_1 = np.expand_dims(s_img,axis = -1)\n        img2 = np.concatenate((arr_3,arr_2,arr_1),axis = -1)\n        height, width = img.shape[:2]\n        img2 = img2.astype('float32')/255.0\n        img = img.astype('float32')/255.0\n        data.append(img2)\n        normal_data.append(img)\n        labels.append(label)\n\n    except:\n        print(i,file_name)\n        print(\"Not possible\")  \ntrain_data = np.array(data)\nprint(train_data.shape)\nnormal_data = np.array(normal_data)\nprint(normal_data.shape)\n\ntrain_labels = np.array(labels)\nprint(train_labels.shape)    \n\nprint('^_^-training data finished-^_^')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T16:59:54.975091Z","iopub.execute_input":"2021-07-07T16:59:54.975422Z","iopub.status.idle":"2021-07-07T17:04:46.778562Z","shell.execute_reply.started":"2021-07-07T16:59:54.975396Z","shell.execute_reply":"2021-07-07T17:04:46.777612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text = []\ndata = []\nlabels = []\nfor i in range(len(l_test)):\n    file_name,label = l_test[i]\n    a,b = file_name.split(\"|\")\n    img = cv2.imread(a)\n    arr_1 = np.empty((480,640))\n    try:\n        with open(b,\"r\") as f:\n            arr = f.readlines()\n            for i in range(len(arr)):\n                arr_2 = []\n                for j in arr[i].split():\n                    arr_2.append(float(j))\n                arr_1[i] = np.asarray(arr_2) \n        img = np.asarray(img)\n        arr_1 = np.asarray(arr_1) \n        edge_roberts = roberts(arr_1)\n        edge_canny = feature.canny(arr_1, sigma=1)\n        edge_canny = np.asarray(edge_canny)\n        img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n        arr_img = cv2.resize(arr_1,(224,224),interpolation = cv2.INTER_CUBIC)\n        s_img = cv2.resize(edge_roberts,(224,224),interpolation = cv2.INTER_CUBIC)\n        r_img = resize(edge_canny, (224,224),anti_aliasing=True)\n        #r_img = cv2.resize(edge_canny,(224,224),interpolation = cv2.INTER_CUBIC)\n        arr_3 = np.expand_dims(arr_img,axis = -1)\n        arr_2 = np.expand_dims(r_img,axis = -1)\n        arr_1 = np.expand_dims(s_img,axis = -1)\n        img2 = np.concatenate((arr_3,arr_2,arr_1),axis = -1)\n        height, width = img.shape[:2]\n        img2 = img2.astype('float32')/255.0\n        img = img.astype('float32')/255.0\n        test_text.append(img2)\n        data.append(img)\n        labels.append(label)\n\n    except:\n        print(i,file_name)\n        print(\"Not possible\")  \n  \n       \ntest_data = np.array(data)\nprint(test_data.shape)\ntest_text = np.array(test_text)\nprint(test_text.shape)\ntest_labels = np.array(labels)\nprint(test_labels.shape)    \n\nprint('^_^-testing data finished-^_^')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T17:04:46.779965Z","iopub.execute_input":"2021-07-07T17:04:46.780466Z","iopub.status.idle":"2021-07-07T17:06:04.66699Z","shell.execute_reply.started":"2021-07-07T17:04:46.780423Z","shell.execute_reply":"2021-07-07T17:06:04.666041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **#CANNY AND prewitt**","metadata":{}},{"cell_type":"code","source":"data = []\nnormal_data = []\nlabels = []\nfor i in range(len(l_train)):\n    file_name,label = l_train[i]\n    a,b = file_name.split(\"|\")\n    img = cv2.imread(a)\n    arr_1 = np.empty((480,640))\n\n    try:\n        with open(b,\"r\") as f:\n            arr = f.readlines()\n            for i in range(len(arr)):\n                arr[i] = arr[i].replace(\",\", \".\")\n                arr_2 = []\n                for j in arr[i].split():\n                    arr_2.append(float(j))\n                arr_1[i] = np.asarray(arr_2) \n        img = np.asarray(img)\n        arr_1 = np.asarray(arr_1)\n        edge_prewitt = prewitt(arr_1)\n        edge_canny = feature.canny(arr_1, sigma=1)\n        edge_canny = np.asarray(edge_canny)\n        img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n        arr_img = cv2.resize(arr_1,(224,224),interpolation = cv2.INTER_CUBIC)\n        r_img = cv2.resize(edge_prewitt,(224,224),interpolation = cv2.INTER_CUBIC)\n        #s_img = cv2.resize(edge_canny,(224,224),interpolation = cv2.INTER_CUBIC)\n        s_img = resize(edge_canny, (224,224),anti_aliasing=True)\n        arr_3 = np.expand_dims(arr_img,axis = -1)\n        arr_2 = np.expand_dims(r_img,axis = -1)\n        arr_1 = np.expand_dims(s_img,axis = -1)\n        img2 = np.concatenate((arr_3,arr_2,arr_1),axis = -1)\n        height, width = img.shape[:2]\n        img2 = img2.astype('float32')/255.0\n        img = img.astype('float32')/255.0\n        data.append(img2)\n        normal_data.append(img)\n        labels.append(label)\n\n    except:\n        print(i,file_name)\n        print(\"Not possible\")  \ntrain_data = np.array(data)\nprint(train_data.shape)\nnormal_data = np.array(normal_data)\nprint(normal_data.shape)\n\ntrain_labels = np.array(labels)\nprint(train_labels.shape)    \n\nprint('^_^-training data finished-^_^')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text = []\ndata = []\nlabels = []\nfor i in range(len(l_test)):\n    file_name,label = l_test[i]\n    a,b = file_name.split(\"|\")\n    img = cv2.imread(a)\n    arr_1 = np.empty((480,640))\n    try:\n        with open(b,\"r\") as f:\n            arr = f.readlines()\n            for i in range(len(arr)):\n                arr_2 = []\n                for j in arr[i].split():\n                    arr_2.append(float(j))\n                arr_1[i] = np.asarray(arr_2) \n        img = np.asarray(img)\n        arr_1 = np.asarray(arr_1) \n        edge_prewitt = prewitt(arr_1)\n        edge_canny = feature.canny(arr_1, sigma=1)\n        edge_canny = np.asarray(edge_canny)\n        img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n        arr_img = cv2.resize(arr_1,(224,224),interpolation = cv2.INTER_CUBIC)\n        s_img = cv2.resize(edge_prewitt,(224,224),interpolation = cv2.INTER_CUBIC)\n        #r_img = cv2.resize(edge_canny,(224,224),interpolation = cv2.INTER_CUBIC)\n        r_img = resize(edge_canny, (224,224),anti_aliasing=True)\n        arr_3 = np.expand_dims(arr_img,axis = -1)\n        arr_2 = np.expand_dims(r_img,axis = -1)\n        arr_1 = np.expand_dims(s_img,axis = -1)\n        img2 = np.concatenate((arr_3,arr_2,arr_1),axis = -1)\n        height, width = img.shape[:2]\n        img2 = img2.astype('float32')/255.0\n        img = img.astype('float32')/255.0\n        test_text.append(img2)\n        data.append(img)\n        labels.append(label)\n\n    except:\n        print(i,file_name)\n        print(\"Not possible\")  \n  \n       \ntest_data = np.array(data)\nprint(test_data.shape)\ntest_text = np.array(test_text)\nprint(test_text.shape)\ntest_labels = np.array(labels)\nprint(test_labels.shape)    \n\nprint('^_^-testing data finished-^_^')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training Model**","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:49:36.182139Z","iopub.execute_input":"2021-07-02T19:49:36.182471Z","iopub.status.idle":"2021-07-02T19:49:44.681638Z","shell.execute_reply.started":"2021-07-02T19:49:36.182422Z","shell.execute_reply":"2021-07-02T19:49:44.680689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom classification_models.keras import Classifiers\n\n# for tensorflow.keras\n# from classification_models.tfkeras import Classifiers\n\nResNet34, preprocess_input = Classifiers.get('resnet34')\nmodel = ResNet34((224, 224, 3), weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:49:44.792284Z","iopub.execute_input":"2021-07-02T19:49:44.792607Z","iopub.status.idle":"2021-07-02T19:49:52.213568Z","shell.execute_reply.started":"2021-07-02T19:49:44.792572Z","shell.execute_reply":"2021-07-02T19:49:52.212498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = preprocess_input(train_data)\ntest_text = preprocess_input(test_text)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:49:52.215198Z","iopub.execute_input":"2021-07-02T19:49:52.215544Z","iopub.status.idle":"2021-07-02T19:49:52.220461Z","shell.execute_reply.started":"2021-07-02T19:49:52.2155Z","shell.execute_reply":"2021-07-02T19:49:52.218757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(224,224,3))\nfe = model(inputs)\nflat = Flatten()(fe)\n\ndense_1 = Dense(4096,activation = 'relu')(flat)\n\ndense = Dense(4096,activation = 'relu')(dense_1)\n\nprediction = Dense(2,activation = 'softmax')(dense)\nin8_model = Model(inputs=[inputs], outputs=[prediction])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:49:53.214879Z","iopub.execute_input":"2021-07-02T19:49:53.21521Z","iopub.status.idle":"2021-07-02T19:49:53.485533Z","shell.execute_reply.started":"2021-07-02T19:49:53.215176Z","shell.execute_reply":"2021-07-02T19:49:53.484703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in8_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])\nin8_model.fit(train_data, train_labels, batch_size = 32,epochs = 40)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:50:00.394238Z","iopub.execute_input":"2021-07-02T19:50:00.394582Z","iopub.status.idle":"2021-07-02T19:52:13.826275Z","shell.execute_reply.started":"2021-07-02T19:50:00.394548Z","shell.execute_reply":"2021-07-02T19:52:13.82545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in8_model.evaluate(test_data,test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T19:52:38.526473Z","iopub.execute_input":"2021-07-02T19:52:38.526819Z","iopub.status.idle":"2021-07-02T19:52:38.987153Z","shell.execute_reply.started":"2021-07-02T19:52:38.526788Z","shell.execute_reply":"2021-07-02T19:52:38.986209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = preprocess_input(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in_model = tf.keras.applications.DenseNet121(input_shape=(224,224,3),\n                                               include_top=False,\n                                               weights='imagenet',classes = 2)\n\ninputs = tf.keras.Input(shape=(224,224,3))\n#inputs2 = tf.keras.Input(shape=(224,224,3))\n\nx = in_model(inputs)\n#input_ = tf.expand_dims(x,axis = 1)\n#x3 = ConvLSTM2D(filters=64, kernel_size=(1,1),padding = \"same\")(input_) \n#x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n#x  = Activation('relu')(x3)\n#x2 = in_model(inputs2)\n#x = Concatenate()([x,x2])\nflat = Flatten()(x)\n\ndense_1 = Dense(320,activation = 'relu')(flat)\n#dense_1 = Dropout(0.5)(dense_1)\ndense_2 = Dense(320,activation = 'relu')(dense_1)\n#dense_2 = Dropout(0.5)(dense_2)\nprediction = Dense(2,activation = 'softmax')(dense_2)\n\nin_pred = Model(inputs = inputs,outputs = prediction)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:29:54.963680Z","iopub.execute_input":"2021-07-07T19:29:54.964008Z","iopub.status.idle":"2021-07-07T19:30:00.464494Z","shell.execute_reply.started":"2021-07-07T19:29:54.963972Z","shell.execute_reply":"2021-07-07T19:30:00.463611Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29089792/29084464 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"in_pred.summary()\nin_pred.compile(optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])\nin_pred.fit(train_data,train_labels,batch_size = 32,epochs = 60)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:30:00.465718Z","iopub.execute_input":"2021-07-07T19:30:00.466054Z","iopub.status.idle":"2021-07-07T19:35:22.190944Z","shell.execute_reply.started":"2021-07-07T19:30:00.466020Z","shell.execute_reply":"2021-07-07T19:35:22.189949Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\ndensenet121 (Functional)     (None, 7, 7, 1024)        7037504   \n_________________________________________________________________\nflatten (Flatten)            (None, 50176)             0         \n_________________________________________________________________\ndense (Dense)                (None, 320)               16056640  \n_________________________________________________________________\ndense_1 (Dense)              (None, 320)               102720    \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 642       \n=================================================================\nTotal params: 23,197,506\nTrainable params: 23,113,858\nNon-trainable params: 83,648\n_________________________________________________________________\nEpoch 1/60\n27/27 [==============================] - 20s 234ms/step - loss: 0.3848 - accuracy: 0.8056\nEpoch 2/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0355 - accuracy: 1.0000\nEpoch 3/60\n27/27 [==============================] - 5s 190ms/step - loss: 0.0185 - accuracy: 1.0000\nEpoch 4/60\n27/27 [==============================] - 5s 190ms/step - loss: 0.0107 - accuracy: 1.0000\nEpoch 5/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0079 - accuracy: 1.0000\nEpoch 6/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0076 - accuracy: 1.0000\nEpoch 7/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0074 - accuracy: 1.0000\nEpoch 8/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0048 - accuracy: 1.0000\nEpoch 9/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0057 - accuracy: 1.0000\nEpoch 10/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0038 - accuracy: 1.0000\nEpoch 11/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0032 - accuracy: 1.0000\nEpoch 12/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0029 - accuracy: 1.0000\nEpoch 13/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0023 - accuracy: 1.0000\nEpoch 14/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0030 - accuracy: 1.0000\nEpoch 15/60\n27/27 [==============================] - 5s 191ms/step - loss: 0.0022 - accuracy: 1.0000\nEpoch 16/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0028 - accuracy: 1.0000\nEpoch 17/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 18/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0021 - accuracy: 1.0000\nEpoch 19/60\n27/27 [==============================] - 5s 191ms/step - loss: 0.0012 - accuracy: 1.0000\nEpoch 20/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 21/60\n27/27 [==============================] - 5s 191ms/step - loss: 0.0018 - accuracy: 1.0000\nEpoch 22/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 23/60\n27/27 [==============================] - 5s 191ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 24/60\n27/27 [==============================] - 5s 188ms/step - loss: 9.6701e-04 - accuracy: 1.0000\nEpoch 25/60\n27/27 [==============================] - 5s 189ms/step - loss: 9.4709e-04 - accuracy: 1.0000\nEpoch 26/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0011 - accuracy: 1.0000\nEpoch 27/60\n27/27 [==============================] - 5s 189ms/step - loss: 9.9438e-04 - accuracy: 1.0000\nEpoch 28/60\n27/27 [==============================] - 5s 190ms/step - loss: 9.2809e-04 - accuracy: 1.0000\nEpoch 29/60\n27/27 [==============================] - 5s 188ms/step - loss: 9.1432e-04 - accuracy: 1.0000\nEpoch 30/60\n27/27 [==============================] - 5s 188ms/step - loss: 7.7792e-04 - accuracy: 1.0000\nEpoch 31/60\n27/27 [==============================] - 5s 188ms/step - loss: 7.7336e-04 - accuracy: 1.0000\nEpoch 32/60\n27/27 [==============================] - 5s 189ms/step - loss: 8.9320e-04 - accuracy: 1.0000\nEpoch 33/60\n27/27 [==============================] - 5s 188ms/step - loss: 7.0315e-04 - accuracy: 1.0000\nEpoch 34/60\n27/27 [==============================] - 5s 191ms/step - loss: 6.6670e-04 - accuracy: 1.0000\nEpoch 35/60\n27/27 [==============================] - 5s 188ms/step - loss: 6.9540e-04 - accuracy: 1.0000\nEpoch 36/60\n27/27 [==============================] - 5s 189ms/step - loss: 6.2195e-04 - accuracy: 1.0000\nEpoch 37/60\n27/27 [==============================] - 5s 189ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 38/60\n27/27 [==============================] - 5s 189ms/step - loss: 6.3572e-04 - accuracy: 1.0000\nEpoch 39/60\n27/27 [==============================] - 5s 188ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 40/60\n27/27 [==============================] - 5s 195ms/step - loss: 6.8705e-04 - accuracy: 1.0000\nEpoch 41/60\n27/27 [==============================] - 5s 187ms/step - loss: 6.4226e-04 - accuracy: 1.0000\nEpoch 42/60\n27/27 [==============================] - 5s 188ms/step - loss: 6.5631e-04 - accuracy: 1.0000\nEpoch 43/60\n27/27 [==============================] - 5s 188ms/step - loss: 5.9072e-04 - accuracy: 1.0000\nEpoch 44/60\n27/27 [==============================] - 5s 189ms/step - loss: 8.4185e-04 - accuracy: 1.0000\nEpoch 45/60\n27/27 [==============================] - 5s 188ms/step - loss: 6.1765e-04 - accuracy: 1.0000\nEpoch 46/60\n27/27 [==============================] - 5s 190ms/step - loss: 5.5928e-04 - accuracy: 1.0000\nEpoch 47/60\n27/27 [==============================] - 5s 190ms/step - loss: 6.8119e-04 - accuracy: 1.0000\nEpoch 48/60\n27/27 [==============================] - 5s 188ms/step - loss: 4.7858e-04 - accuracy: 1.0000\nEpoch 49/60\n27/27 [==============================] - 5s 189ms/step - loss: 5.3082e-04 - accuracy: 1.0000\nEpoch 50/60\n27/27 [==============================] - 5s 188ms/step - loss: 4.3627e-04 - accuracy: 1.0000\nEpoch 51/60\n27/27 [==============================] - 5s 189ms/step - loss: 5.8366e-04 - accuracy: 1.0000\nEpoch 52/60\n27/27 [==============================] - 5s 188ms/step - loss: 5.0225e-04 - accuracy: 1.0000\nEpoch 53/60\n27/27 [==============================] - 5s 190ms/step - loss: 3.6392e-04 - accuracy: 1.0000\nEpoch 54/60\n27/27 [==============================] - 5s 188ms/step - loss: 4.9200e-04 - accuracy: 1.0000\nEpoch 55/60\n27/27 [==============================] - 5s 189ms/step - loss: 5.4823e-04 - accuracy: 1.0000\nEpoch 56/60\n27/27 [==============================] - 5s 188ms/step - loss: 4.2961e-04 - accuracy: 1.0000\nEpoch 57/60\n27/27 [==============================] - 5s 188ms/step - loss: 3.9057e-04 - accuracy: 1.0000\nEpoch 58/60\n27/27 [==============================] - 5s 189ms/step - loss: 3.7441e-04 - accuracy: 1.0000\nEpoch 59/60\n27/27 [==============================] - 5s 190ms/step - loss: 3.4612e-04 - accuracy: 1.0000\nEpoch 60/60\n27/27 [==============================] - 5s 189ms/step - loss: 3.7639e-04 - accuracy: 1.0000\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f93fdb8bb90>"},"metadata":{}}]},{"cell_type":"code","source":"in_pred.evaluate(test_data,test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T19:35:51.644818Z","iopub.execute_input":"2021-07-07T19:35:51.645216Z","iopub.status.idle":"2021-07-07T19:35:52.264652Z","shell.execute_reply.started":"2021-07-07T19:35:51.645183Z","shell.execute_reply":"2021-07-07T19:35:52.263877Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"8/8 [==============================] - 0s 56ms/step - loss: 8.5441 - accuracy: 0.4647\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[8.544113159179688, 0.46473029255867004]"},"metadata":{}}]},{"cell_type":"code","source":"test_ = in_pred.predict(test_text)\nY_pred= np.argmax(test_labels, axis=1)\nvgg19 = np.argmax(test_, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T18:42:35.253606Z","iopub.execute_input":"2021-07-07T18:42:35.253961Z","iopub.status.idle":"2021-07-07T18:42:36.817627Z","shell.execute_reply.started":"2021-07-07T18:42:35.253928Z","shell.execute_reply":"2021-07-07T18:42:36.816703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\nprint(confusion_matrix(Y_pred,vgg19))\nprint(classification_report(Y_pred,vgg19))\nprint(accuracy_score(Y_pred,vgg19))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T18:42:36.819138Z","iopub.execute_input":"2021-07-07T18:42:36.819471Z","iopub.status.idle":"2021-07-07T18:42:36.840176Z","shell.execute_reply.started":"2021-07-07T18:42:36.819435Z","shell.execute_reply":"2021-07-07T18:42:36.839392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}